{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Inno732/Defi_IA_1_2023_2024/blob/main/XAI_Gradcam_classification_tf_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5UwQZ_mIyfy"
      },
      "source": [
        "#**1. Intaller le module d'explicabilité \"tf-explain\"**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCWb0dvVJ2tA"
      },
      "outputs": [],
      "source": [
        "!pip install tf-explain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wpOwqc3Irtl"
      },
      "source": [
        "#**2. Importer les libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "K3GcNuGHIrB-"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tf_explain\n",
        "from tf_explain.core.grad_cam import GradCAM\n",
        "from tf_explain.core.smoothgrad import SmoothGrad\n",
        "from keras.models import load_model\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92soAlxVIWcO"
      },
      "source": [
        "#**3. Télécharger la base d'images de test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GMnzHDaWXYB"
      },
      "outputs": [],
      "source": [
        "!rm -rf sample_data\n",
        "!wget https://nextcloud.ig.umons.ac.be/s/RsZpqtYfDgYzKxr/download/test.zip\n",
        "!unzip test.zip\n",
        "! rm test.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CUpXa5k9kjZM"
      },
      "outputs": [],
      "source": [
        "!printf '%s\\n' 'fire' 'no_fire' 'start_fire'> classes.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "joVdiXXIlTeU"
      },
      "outputs": [],
      "source": [
        "dataset_name='test'\n",
        "#test_dataset = os.path.join('bases/', dataset_name)\n",
        "classes_path = \"classes.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Socf8GLwk4ry"
      },
      "outputs": [],
      "source": [
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "\tdataset_name,\n",
        "\tbatch_size= 8,      # Taille du mini-batch\n",
        "  label_mode= 'categorical'    # Conversion au format One-Hot\n",
        ")                             # Generates a 'tf.data.Dataset' from image files in a directory (train_dataset)\n",
        "print(test_ds.class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14lVSNPV368b"
      },
      "source": [
        "#**4. Télécharger votre modèle**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggjyfvnF3oDH"
      },
      "outputs": [],
      "source": [
        "!wget https://nextcloud.ig.umons.ac.be/s/p2xNRJZqZ5zCrW6/download/small_MobileNetV2_2023_test.h5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5LNrrgXo7vC"
      },
      "outputs": [],
      "source": [
        "!wget https://nextcloud.ig.umons.ac.be/s/p2xNRJZqZ5zCrW6/download/model_VGG16_8r5eqnu.h5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://nextcloud.ig.umons.ac.be/s/p2xNRJZqZ5zCrW6/download/model_VGG19_epD3OKv.h5\n",
        "!wget https://nextcloud.ig.umons.ac.be/s/p2xNRJZqZ5zCrW6/download/model_rsnt50.h5\n",
        "!wget https://nextcloud.ig.umons.ac.be/s/p2xNRJZqZ5zCrW6/download/model_xception_1.h5\n",
        "!wget https://nextcloud.ig.umons.ac.be/s/p2xNRJZqZ5zCrW6/download/model_DsNt121_1.h5"
      ],
      "metadata": {
        "id": "Y-Rq6s42M9gX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-63CipOuKS9Q"
      },
      "outputs": [],
      "source": [
        "# Load pretrained model or your own\n",
        "model = load_model(\"small_MobileNetV2_2023_test.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "3RFsc8v7pNIw"
      },
      "outputs": [],
      "source": [
        "model_VGG16 = load_model(\"model_VGG16_8r5eqnu.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_VGG19 = load_model(\"model_VGG19_epD3OKv.h5\")"
      ],
      "metadata": {
        "id": "g9zNzCcwMr2H"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_DsNt121 = load_model(\"model_DsNt121_1.h5\")"
      ],
      "metadata": {
        "id": "_IIbsipIMvGi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_rsnt50 = load_model(\"model_rsnt50.h5\")"
      ],
      "metadata": {
        "id": "un8QgtVWMxNi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_xception = load_model(\"model_xception_1.h5\")"
      ],
      "metadata": {
        "id": "p7lqsdUqMyvJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "38m0SYHYKqwu"
      },
      "outputs": [],
      "source": [
        "input_dim =224"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNcZol-8JJxf"
      },
      "source": [
        "#**5. Définir la classe à expliquer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "AfsCqI69Hwnv"
      },
      "outputs": [],
      "source": [
        "className=\"Fire\"\n",
        "#className=\"start_fire\"\n",
        "!mkdir -p className/className"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = test_ds.class_names"
      ],
      "metadata": {
        "id": "PqzN9D9D5gjR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fxEBx18JTkT"
      },
      "source": [
        "#**6. Sélectionner 3 images de test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-VcqWbXLIKmp"
      },
      "outputs": [],
      "source": [
        "images_to_test = [\"test/fire/test002.jpg\",\n",
        "                  \"test/fire/test005.jpg\",\n",
        "                  \"test/fire/test013.jpg\",\n",
        "                  \"test/fire/F_2062.jpg\",\n",
        "                  \"test/fire/F_2063.jpg\",\n",
        "                  \"test/fire/F_2064.jpg\",\n",
        "                  \"test/fire/F_2066.jpg\",\n",
        "                  \"test/fire/F_2067.jpg\",\n",
        "                  \"test/fire/F_2080.jpg\",\n",
        "                  \"test/no_fire/img31.jpg\",\n",
        "                  \"test/fire/F_2062.jpg\",\n",
        "                  \"test/start_fire/test101.jpg\",\n",
        "                  \"test/start_fire/test122.jpg\",\n",
        "                  \"test/start_fire/NorthAmerica (79).png\",\n",
        "                  \"test/start_fire/test106.jpg\",\n",
        "                  \"test/start_fire/test118.jpg\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5popuYkJZcq"
      },
      "source": [
        "#**4. Expliquer le modèle avec la méthode XAI \"GradCAM\"**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2RyLHFlpcZF"
      },
      "outputs": [],
      "source": [
        "for image_path in images_to_test:\n",
        "    #imnum=[]\n",
        "    print(image_path)\n",
        "    # Load to the correct format and predict the current image\n",
        "    img0 = tf.keras.preprocessing.image.load_img(image_path, target_size=(input_dim,input_dim))\n",
        "    img = tf.keras.preprocessing.image.img_to_array(img0)\n",
        "\n",
        "    data = ([img], None)\n",
        "    xy=np.expand_dims(img,axis=0)\n",
        "    myTuple=(xy,None)\n",
        "\n",
        "    # Start explainer\n",
        "    #explainer = SmoothGrad()\n",
        "    explainer = GradCAM()\n",
        "    grid = explainer.explain(myTuple, model_VGG16, class_index=1)\n",
        "    temp = np.concatenate((img,grid),axis=1)\n",
        "    fig, axs = plt.subplots(1, 3)\n",
        "    axs[0].imshow(img.astype(np.uint8))\n",
        "    axs[0].set_title(\"input\")\n",
        "    axs[1].imshow(grid.astype(np.uint8))\n",
        "    axs[1].set_title(\"XAI\")\n",
        "\n",
        "    fig.set_figheight(15)\n",
        "    fig.set_figwidth(15)\n",
        "\n",
        "\n",
        "    pred_VGG16 = model_VGG16.predict(xy,batch_size=1)[0]\n",
        "    print(pred_VGG16)\n",
        "    for (pos,prob) in enumerate(pred_VGG16):\n",
        "      pos == np.argmax(pred_VGG16)\n",
        "      img = cv2.imread(image_path)\n",
        "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "      font = cv2.FONT_HERSHEY_COMPLEX\n",
        "      textsize = cv2.getTextSize(className, font, 0.7, 2)[0]\n",
        "      textX = (img.shape[1] - textsize[0]) / 2\n",
        "      textY = (img.shape[0] + textsize[1]) / 2\n",
        "      cv2.putText(img, classes[np.argmax(pred_VGG16)], (int(textX), int(textY)), font, 4.7, (255,255,255), 5, cv2.LINE_AA)\n",
        "      axs[2].imshow(img)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yd2O1Yn-jij5"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "\n",
        "axes=[]\n",
        "fig = plt.figure()\n",
        "fig = plt.figure(figsize=(18,9))\n",
        "\n",
        "classes = test_ds.class_names\n",
        "liste_image = images_to_test\n",
        "compteur = 1\n",
        "for image_path in liste_image:\n",
        "    # predict VGG16\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    x = tf.keras.utils.img_to_array(img,data_format='channels_last')\n",
        "    x = tf.keras.preprocessing.image.smart_resize(x, size=(299,299))\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    pred = model_VGG16.predict(x,batch_size=1)[0]\n",
        "\n",
        "\n",
        "    for (pos,prob) in enumerate(pred):\n",
        "            class_name = classes[pos]\n",
        "            if (pos == np.argmax(pred)) :\n",
        "                img = cv2.imread(image_path)\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                font = cv2.FONT_HERSHEY_COMPLEX\n",
        "                textsize = cv2.getTextSize(class_name, font, 1, 2)[0]\n",
        "                textX = (img.shape[1] - textsize[0]) / 2\n",
        "                textY = (img.shape[0] + textsize[1]) / 2\n",
        "                cv2.putText(img, class_name, (int(textX)-10, int(textY)), font, 2, (255,0,0), 6, cv2.LINE_AA)\n",
        "                axes.append(fig.add_subplot(4, 4, compteur))\n",
        "                plt.imshow(img)\n",
        "                compteur += 1\n",
        "            # print(\"Top %d ====================\" % (i + 1))\n",
        "            print(\"Class Name : %s\" % (classes[np.argmax(pred)]), \"---\", \"Class Probability: %.2f%%\" % (prob*100))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLqLYIdPH23s"
      },
      "outputs": [],
      "source": [
        "for image_path in images_to_test:\n",
        "    #imnum=[]\n",
        "    print(image_path)\n",
        "    # Load to the correct format and predict the current image\n",
        "    img0 = tf.keras.preprocessing.image.load_img(image_path, target_size=(input_dim,input_dim))\n",
        "    img = tf.keras.preprocessing.image.img_to_array(img0)\n",
        "\n",
        "    data = ([img], None)\n",
        "    xy=np.expand_dims(img,axis=0)\n",
        "    myTuple=(xy,None)\n",
        "\n",
        "    # Start explainer\n",
        "    #explainer = SmoothGrad()\n",
        "    explainer = GradCAM()\n",
        "    grid = explainer.explain(myTuple, model, class_index=1)\n",
        "    temp = np.concatenate((img,grid),axis=1)\n",
        "    fig, axs = plt.subplots(1, 3)\n",
        "    axs[0].imshow(img.astype(np.uint8))\n",
        "    axs[0].set_title(\"input\")\n",
        "    axs[1].imshow(grid.astype(np.uint8))\n",
        "    axs[1].set_title(\"XAI\")\n",
        "\n",
        "    fig.set_figheight(15)\n",
        "    fig.set_figwidth(15)\n",
        "\n",
        "\n",
        "    pred = model.predict(xy,batch_size=1)[0]\n",
        "    print(pred)\n",
        "    for (pos,prob) in enumerate(pred):\n",
        "      pos == np.argmax(pred)\n",
        "      img = cv2.imread(image_path)\n",
        "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "      font = cv2.FONT_HERSHEY_COMPLEX\n",
        "      textsize = cv2.getTextSize(className, font, 0.7, 2)[0]\n",
        "      textX = (img.shape[1] - textsize[0]) / 2\n",
        "      textY = (img.shape[0] + textsize[1]) / 2\n",
        "      cv2.putText(img, classes[np.argmax(pred)], (int(textX), int(textY)), font, 4.7, (255,255,255), 5, cv2.LINE_AA)\n",
        "      axs[2].imshow(img)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFKjf1g16OK8"
      },
      "outputs": [],
      "source": [
        "for image_path in images_to_test:\n",
        "    #imnum=[]\n",
        "    print(image_path)\n",
        "    # Load to the correct format and predict the current image\n",
        "    img0 = tf.keras.preprocessing.image.load_img(image_path, target_size=(input_dim,input_dim))\n",
        "    img = tf.keras.preprocessing.image.img_to_array(img0)\n",
        "\n",
        "    data = ([img], None)\n",
        "    xy=np.expand_dims(img,axis=0)\n",
        "    myTuple=(xy,None)\n",
        "\n",
        "    # Start explainer\n",
        "    #explainer = SmoothGrad()\n",
        "    explainer = GradCAM()\n",
        "    grid = explainer.explain(myTuple, model_VGG19, class_index=1)\n",
        "    temp = np.concatenate((img,grid),axis=1)\n",
        "    fig, axs = plt.subplots(1, 3)\n",
        "    axs[0].imshow(img.astype(np.uint8))\n",
        "    axs[0].set_title(\"input\")\n",
        "    axs[1].imshow(grid.astype(np.uint8))\n",
        "    axs[1].set_title(\"XAI\")\n",
        "\n",
        "    fig.set_figheight(15)\n",
        "    fig.set_figwidth(15)\n",
        "\n",
        "\n",
        "    pred_VGG19 = model_VGG19.predict(xy,batch_size=1)[0]\n",
        "    print(pred_VGG19)\n",
        "    for (pos,prob) in enumerate(pred_VGG19):\n",
        "      pos == np.argmax(pred_VGG19)\n",
        "      img = cv2.imread(image_path)\n",
        "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "      font = cv2.FONT_HERSHEY_COMPLEX\n",
        "      textsize = cv2.getTextSize(className, font, 0.7, 2)[0]\n",
        "      textX = (img.shape[1] - textsize[0]) / 2\n",
        "      textY = (img.shape[0] + textsize[1]) / 2\n",
        "      cv2.putText(img, classes[np.argmax(pred_VGG19)], (int(textX), int(textY)), font, 4.7, (255,255,255), 5, cv2.LINE_AA)\n",
        "      axs[2].imshow(img)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QWl5Sng6Ade"
      },
      "outputs": [],
      "source": [
        "for image_path in images_to_test:\n",
        "    #imnum=[]\n",
        "    print(image_path)\n",
        "    # Load to the correct format and predict the current image\n",
        "    img0 = tf.keras.preprocessing.image.load_img(image_path, target_size=(input_dim,input_dim))\n",
        "    img = tf.keras.preprocessing.image.img_to_array(img0)\n",
        "\n",
        "    data = ([img], None)\n",
        "    xy=np.expand_dims(img,axis=0)\n",
        "    myTuple=(xy,None)\n",
        "\n",
        "    # Start explainer\n",
        "    #explainer = SmoothGrad()\n",
        "    explainer = GradCAM()\n",
        "    grid = explainer.explain(myTuple, model_DsNt121, class_index=1)\n",
        "    temp = np.concatenate((img,grid),axis=1)\n",
        "    fig, axs = plt.subplots(1, 3)\n",
        "    axs[0].imshow(img.astype(np.uint8))\n",
        "    axs[0].set_title(\"input\")\n",
        "    axs[1].imshow(grid.astype(np.uint8))\n",
        "    axs[1].set_title(\"XAI\")\n",
        "\n",
        "    fig.set_figheight(15)\n",
        "    fig.set_figwidth(15)\n",
        "\n",
        "\n",
        "    pred_DsNt121 = model_DsNt121.predict(xy,batch_size=1)[0]\n",
        "    print(pred_DsNt121)\n",
        "    for (pos,prob) in enumerate(pred_DsNt121):\n",
        "      pos == np.argmax(pred_DsNt121)\n",
        "      img = cv2.imread(image_path)\n",
        "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "      font = cv2.FONT_HERSHEY_COMPLEX\n",
        "      textsize = cv2.getTextSize(className, font, 0.7, 2)[0]\n",
        "      textX = (img.shape[1] - textsize[0]) / 2\n",
        "      textY = (img.shape[0] + textsize[1]) / 2\n",
        "      cv2.putText(img, classes[np.argmax(pred_DsNt121)], (int(textX), int(textY)), font, 4.7, (255,255,255), 5, cv2.LINE_AA)\n",
        "      axs[2].imshow(img)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-qcZVbo6itj"
      },
      "outputs": [],
      "source": [
        "for image_path in images_to_test:\n",
        "    #imnum=[]\n",
        "    print(image_path)\n",
        "    # Load to the correct format and predict the current image\n",
        "    img0 = tf.keras.preprocessing.image.load_img(image_path, target_size=(input_dim,input_dim))\n",
        "    img = tf.keras.preprocessing.image.img_to_array(img0)\n",
        "\n",
        "    data = ([img], None)\n",
        "    xy=np.expand_dims(img,axis=0)\n",
        "    myTuple=(xy,None)\n",
        "\n",
        "    # Start explainer\n",
        "    #explainer = SmoothGrad()\n",
        "    explainer = GradCAM()\n",
        "    grid = explainer.explain(myTuple, model_xception, class_index=1)\n",
        "    temp = np.concatenate((img,grid),axis=1)\n",
        "    fig, axs = plt.subplots(1, 3)\n",
        "    axs[0].imshow(img.astype(np.uint8))\n",
        "    axs[0].set_title(\"input\")\n",
        "    axs[1].imshow(grid.astype(np.uint8))\n",
        "    axs[1].set_title(\"XAI\")\n",
        "\n",
        "    fig.set_figheight(15)\n",
        "    fig.set_figwidth(15)\n",
        "\n",
        "\n",
        "    pred_xception = model_xception.predict(xy,batch_size=1)[0]\n",
        "    print(pred_xception)\n",
        "    for (pos,prob) in enumerate(pred_xception):\n",
        "      pos == np.argmax(pred_xception)\n",
        "      img = cv2.imread(image_path)\n",
        "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "      font = cv2.FONT_HERSHEY_COMPLEX\n",
        "      textsize = cv2.getTextSize(className, font, 0.7, 2)[0]\n",
        "      textX = (img.shape[1] - textsize[0]) / 2\n",
        "      textY = (img.shape[0] + textsize[1]) / 2\n",
        "      cv2.putText(img, classes[np.argmax(pred_xception)], (int(textX), int(textY)), font, 4.7, (255,255,255), 5, cv2.LINE_AA)\n",
        "      axs[2].imshow(img)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvaNJqaR6bko"
      },
      "outputs": [],
      "source": [
        "for image_path in images_to_test:\n",
        "    #imnum=[]\n",
        "    print(image_path)\n",
        "    # Load to the correct format and predict the current image\n",
        "    img0 = tf.keras.preprocessing.image.load_img(image_path, target_size=(input_dim,input_dim))\n",
        "    img = tf.keras.preprocessing.image.img_to_array(img0)\n",
        "\n",
        "    data = ([img], None)\n",
        "    xy=np.expand_dims(img,axis=0)\n",
        "    myTuple=(xy,None)\n",
        "\n",
        "    # Start explainer\n",
        "    #explainer = SmoothGrad()\n",
        "    explainer = GradCAM()\n",
        "    grid = explainer.explain(myTuple, model_rsnt50, class_index=1)\n",
        "    temp = np.concatenate((img,grid),axis=1)\n",
        "    fig, axs = plt.subplots(1, 3)\n",
        "    axs[0].imshow(img.astype(np.uint8))\n",
        "    axs[0].set_title(\"input\")\n",
        "    axs[1].imshow(grid.astype(np.uint8))\n",
        "    axs[1].set_title(\"XAI\")\n",
        "\n",
        "    fig.set_figheight(15)\n",
        "    fig.set_figwidth(15)\n",
        "\n",
        "\n",
        "    pred_rsnt50 = model_rsnt50.predict(xy,batch_size=1)[0]\n",
        "    print(pred_rsnt50)\n",
        "    for (pos,prob) in enumerate(pred_rsnt50):\n",
        "      pos == np.argmax(pred_rsnt50)\n",
        "      img = cv2.imread(image_path)\n",
        "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "      font = cv2.FONT_HERSHEY_COMPLEX\n",
        "      textsize = cv2.getTextSize(className, font, 0.7, 2)[0]\n",
        "      textX = (img.shape[1] - textsize[0]) / 2\n",
        "      textY = (img.shape[0] + textsize[1]) / 2\n",
        "      cv2.putText(img, classes[np.argmax(pred_rsnt50)], (int(textX), int(textY)), font, 4.7, (255,255,255), 5, cv2.LINE_AA)\n",
        "      axs[2].imshow(img)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwQrnhz-n8sg"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "im = (Image.open('test/fire/F_2062.jpg'))\n",
        "im"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}